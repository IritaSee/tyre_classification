{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWYNjoLE3oHO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "# from tensorflow.keras.applications import MobileNetV2 as MobileNet\n",
        "#kita pake mobilenet yang dari dosen pembimbing\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD7N5m0mp3r7",
        "outputId": "12d7467e-f1dd-42f3-c2b0-db85d3dca9f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#cara masukin dataset dari email ke drive:\n",
        "# kita add shortcut dulu folder nya\n",
        "# terus, pas kita mau add shortcut, inget inget dimana kita taruhnya, dan namanya, dan masukin ke sini:\n",
        "data_path = '/content/drive/MyDrive/tyres_dataset/tyre/'\n",
        "\n",
        "# dataset link: https://drive.google.com/drive/folders/1EqTFf8pUf1cjdxBfqJJu4QHPqDK6Gtwo?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA2VE4b0jbUr"
      },
      "outputs": [],
      "source": [
        "def mobilenet(input_shape, n_classes, activation_func):\n",
        "  \n",
        "  def mobilenet_block(x, f, s=1):\n",
        "    x = DepthwiseConv2D(3, strides=s, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    \n",
        "    x = Conv2D(f, 1, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "    \n",
        "    \n",
        "  input = Input(input_shape)\n",
        "\n",
        "  x = Conv2D(32, 3, strides=2, padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = ReLU()(x)\n",
        "\n",
        "  x = mobilenet_block(x, 64)\n",
        "  x = mobilenet_block(x, 128, 2)\n",
        "  x = mobilenet_block(x, 128)\n",
        "\n",
        "  x = mobilenet_block(x, 256, 2)\n",
        "  x = mobilenet_block(x, 256)\n",
        "\n",
        "  x = mobilenet_block(x, 512, 2)\n",
        "  for _ in range(5):\n",
        "    x = mobilenet_block(x, 512)\n",
        "\n",
        "  x = mobilenet_block(x, 1024, 2)\n",
        "  x = mobilenet_block(x, 1024)\n",
        "  \n",
        "  x = GlobalAvgPool2D()(x)\n",
        "  \n",
        "  output = Dense(n_classes, activation=activation_func)(x)\n",
        "  \n",
        "  model = Model(input, output)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U04-rUq_6sF"
      },
      "outputs": [],
      "source": [
        "#network: mobilenet\n",
        "#preprocesing: resize, augmentasi (rotasi 90)\n",
        "#aktivasi: softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfYOd5psELW4",
        "outputId": "22931524-a410-4e75-8c97-d3d8f6763849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 832 images belonging to 2 classes.\n",
            "Found 207 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.,\n",
        "                                   rotation_range=90,\n",
        "                                   #width_shift_range=0.2,\n",
        "                                   #height_shift_range=0.2,\n",
        "                                   zoom_range=0.1,\n",
        "                                   validation_split = 0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(data_path, \n",
        "                                                    shuffle = True,\n",
        "                                                    batch_size=8, ## <- jadi salah satu parameter!\n",
        "                                                    class_mode='binary',\n",
        "                                                    subset = 'training',\n",
        "                                                    target_size=(150,150))\n",
        "\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    data_path, \n",
        "    shuffle = True,\n",
        "    batch_size=8,\n",
        "    class_mode='binary',\n",
        "    subset = 'validation',\n",
        "    target_size=(150,150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkfqV8xMx74J"
      },
      "outputs": [],
      "source": [
        "#using pretrained, \n",
        "\n",
        "# #pretrained = MobileNet(include_top=False, weights='imagenet',classes=2, dropout=0.1, input_shape=(150,150,3))\n",
        "# pretrained = MobileNet(include_top=False, weights='imagenet',classes=2, input_shape=(150,150,3))\n",
        "# pretrained.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dLUSvvtyPWe"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.Sequential([\n",
        "#         tf.keras.layers.InputLayer( input_shape=(150,150,3)),\n",
        "#         pretrained,\n",
        "#         tf.keras.layers.Flatten(),\n",
        "#         tf.keras.layers.Dense(512,activation='relu'),\n",
        "#         tf.keras.layers.Dropout(0.5),\n",
        "#         tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "#     ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBzAR0FklmgS"
      },
      "outputs": [],
      "source": [
        "# using bu sofi's Recipe: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wApmhhGhlvbW"
      },
      "outputs": [],
      "source": [
        "input_shape = 64,64, 3\n",
        "n_classes = 1 \n",
        "activation_func = 'sigmoid'\n",
        "\n",
        "model = mobilenet(input_shape, n_classes, activation_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8hNovj5l2gL",
        "outputId": "7585522a-4073-4eae-f9f6-c1bbb6576ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d (Depthwise  (None, 32, 32, 32)       320       \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        2112      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_1 (Depthwi  (None, 16, 16, 64)       640       \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       8320      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_2 (Depthwi  (None, 16, 16, 128)      1280      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 128)       16512     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_3 (Depthwi  (None, 8, 8, 128)        1280      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         33024     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_4 (Depthwi  (None, 8, 8, 256)        2560      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_9 (ReLU)              (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 256)         65792     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 8, 8, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_10 (ReLU)             (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_5 (Depthwi  (None, 4, 4, 256)        2560      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_11 (ReLU)             (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 512)         131584    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_12 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_6 (Depthwi  (None, 4, 4, 512)        5120      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_13 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_14 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_7 (Depthwi  (None, 4, 4, 512)        5120      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_15 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_16 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_8 (Depthwi  (None, 4, 4, 512)        5120      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_17 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_18 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_9 (Depthwi  (None, 4, 4, 512)        5120      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_19 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 4, 4, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_20 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_10 (Depthw  (None, 4, 4, 512)        5120      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_21 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 4, 4, 512)         262656    \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_22 (ReLU)             (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_11 (Depthw  (None, 2, 2, 512)        5120      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 2, 2, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_23 (ReLU)             (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 2, 2, 1024)        525312    \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 2, 2, 1024)       4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_24 (ReLU)             (None, 2, 2, 1024)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_12 (Depthw  (None, 2, 2, 1024)       10240     \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 2, 2, 1024)       4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_25 (ReLU)             (None, 2, 2, 1024)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 2, 2, 1024)        1049600   \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 2, 2, 1024)       4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_26 (ReLU)             (None, 2, 2, 1024)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,240,833\n",
            "Trainable params: 3,218,945\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZGGWZQVyx9V"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'Adam', loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI0sEPSmyqf-",
        "outputId": "c868937b-2586-4fc3-b6a3-30bb8d169bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "104/104 [==============================] - 223s 2s/step - loss: 0.0000e+00 - accuracy: 0.5385 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 59s 567ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 59s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 60s 576ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 59s 568ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 59s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 59s 569ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 59s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 59s 569ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 59s 567ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 60s 575ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 59s 568ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 59s 566ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 58s 561ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 58s 561ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 58s 563ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 58s 560ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 58s 562ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 59s 562ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 59s 568ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 59s 566ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 59s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 59s 566ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 59s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 59s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 60s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 60s 577ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 59s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 60s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 59s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 59s 569ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 59s 570ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 59s 569ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 59s 569ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 59s 569ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 59s 568ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 60s 576ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 59s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 59s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 59s 568ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 60s 579ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 60s 576ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 60s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 60s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 60s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 60s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 60s 576ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 60s 577ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 60s 575ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 60s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 60s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 60s 577ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 60s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 60s 578ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 60s 575ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 59s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 60s 575ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 60s 576ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 60s 576ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 60s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 60s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 60s 575ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 59s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 60s 576ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 59s 572ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 60s 573ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 60s 571ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 60s 575ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 60s 574ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 60s 577ms/step - loss: 0.0000e+00 - accuracy: 0.5192 - val_loss: 0.0000e+00 - val_accuracy: 0.5217\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator, validation_data = valid_generator,\n",
        "                    epochs=100\n",
        "                    ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyGEHSI402to",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "1d107493-7ea8-4574-a88d-7085665f8b84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1) # jumlah row, jumlah column, column/row berapa\n",
        "plt.plot(train_acc, label='Training')\n",
        "plt.plot(val_acc, label='Validation')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2) # jumlah row, jumlah column, column/row berapa\n",
        "plt.plot(train_loss, label='Training')\n",
        "plt.plot(val_loss, label='Validation')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWjpxQtd06i8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f4a992-4f08-4976-fda4-2ee230e6617f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [99, 108]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.69       108\n",
            "           1       0.00      0.00      0.00        99\n",
            "\n",
            "    accuracy                           0.52       207\n",
            "   macro avg       0.26      0.50      0.34       207\n",
            "weighted avg       0.27      0.52      0.36       207\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "new_model = model\n",
        "\n",
        "probabilities = new_model.predict(valid_generator)\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for prob in probabilities:\n",
        "   best_index = np.argmax(prob)\n",
        "   predictions.append(best_index)\n",
        "\n",
        "labels = valid_generator.classes\n",
        "tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
        "cm = [[tp, fp],\n",
        "      [fn, tn]]\n",
        "cr = classification_report(labels, predictions)\n",
        "print(cm)\n",
        "print(cr)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('kualitas_ban_100Epochs.h5')"
      ],
      "metadata": {
        "id": "EMtQuIS9h12S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ttAtCfBsmhVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Kualitas_Ban 100 Epochs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}